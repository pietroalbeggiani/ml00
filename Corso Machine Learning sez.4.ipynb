{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sezione 4: regolarizzazione e modelli regolarizzati\n",
    "\n",
    "## lezioni 27 - 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduciamo due nuovi concetti: il Bias e la varianza\n",
    "#### Bias: \n",
    "Non è da intendersi come l'intercetta del nostro modello, ma è una metrica che misura quanto distanti sono le nostre previsioni da quelle corrette, se dovessimo costruire piu volte il modello utilizzando siversi dataset. In pratica misura l'errore sistematico del modello che non è dato dalla casualita dei dati che gli vengono forniti.\n",
    "\n",
    "#### Varianza:\n",
    "E' una metrica che misura la differenza delle predizioni se addestriamo piu volte il modello du diversi dataset.\n",
    "In pratica ci dice quanto il modello è sensibile alla casualita de dati del dataset di addestramento, il trainingset.\n",
    "\n",
    "Bias e varianza sono altamente correlati: infatti se aumenta uno diminuisce l'altro.\n",
    "Il nostro lavoro è di riuscire a trovare la giusta combinazione per ottenere bias e varianza che siano entrami i piu piccoli possibile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nel video della lezione si ha un esempio di underfitting e di overfitting:\n",
    "    \n",
    "si ha underfitting se la varianza è bassa ma il bias è alto, vuol dire che il modello è troppo semplice e generico.\n",
    "\n",
    "Si ha overfitting se la varianza è elevata e il bias basso, vuol dire che il modello è troppo complesso, e funziona bene solo per i dati con cui è satto allenato, il trainingset, mentre se lo si fa lavorare con altri dataset lavorera male.\n",
    "\n",
    "Come riconoscere l'overfitting?\n",
    "E' molto semplice, infatti dopo aver addestrato il modello basta confrontare l'errore sul set di addestramento con quello sul set di test. Se quest ultimo è molto piu grande, allora molto probabilmente il nostro modello soffre di overfitting.\n",
    "\n",
    "Come possiamo contrastare l'overfitting?\n",
    "Bisogna semplificare il modello, rimuovendo alcune proprieta. Nel nostro caso potremmo provare a ridurre il grado del polinomio.\n",
    "\n",
    "Questa soluzione è semplice, ma non funziona sempre perche si rischia di perdere informazioni importanti insieme alle proprieta che decidiamo di escludere.\n",
    "\n",
    "La seconda soluzione, che funziona meglio, consiste nel regolarizzare il nostro modello, penalizzando i pesi delle proprieta, applicando alcune tecniche che ora vediamo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Riconoscere l'overfitting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "l'overfitting è un problema che si manifesta nel momento in cui un modello eccessivamente complesso non riesce a generalizzare su dati non visti in addestramento. \n",
    "Ora vediamo come riconoscerlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iniziamo caricando le librerie necessarie:\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  PRATIO  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296.0    15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242.0    17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242.0    17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222.0    18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222.0    18.7   \n",
       "\n",
       "        B  LSTAT  MEDV  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  \n",
       "3  394.63   2.94  33.4  \n",
       "4  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# carichiamo il dataset all'interno di un dataframe:\n",
    "\n",
    "boston = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data\", sep='\\s+', \n",
    "                     names=[\"CRIM\", \"ZN\",\"INDUS\",\"CHAS\",\"NOX\",\"RM\",\"AGE\",\"DIS\",\"RAD\",\"TAX\",\"PRATIO\",\"B\",\"LSTAT\",\"MEDV\"])\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#e creiamo gli array numpy per addestrament e test:\n",
    "\n",
    "X = boston.drop('MEDV',axis=1).values\n",
    "Y = boston['MEDV'].values\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "proviamo a creare un problema di overfitting:\n",
    "per farlo creiamo nuove proprieta polinomiali per ogni proprieta del dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_feats = PolynomialFeatures(degree=2)\n",
    "X_train_poly = poly_feats.fit_transform(X_train)\n",
    "X_test_poly = poly_feats.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(354, 105)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vedaimo la dimensione del nostro test di addestramento:\n",
    "X_train_poly.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "354 esempi e 105 proprieta: è molto complesso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prima di eseguire la regressione, standardizziamo il dataset:\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train_poly = ss.fit_transform(X_train_poly)\n",
    "X_test_poly = ss.transform(X_test_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ora eseguiamo la nostra regressione lineare.\n",
    "\n",
    "ll = LinearRegression()\n",
    "ll.fit(X_train_poly, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adesso eseguiamo la predizione, ma la facciamo sul trainset piuttosto che sul testset:\n",
    "\n",
    "Y_pred_train = ll.predict(X_train_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adesso calcoliamo l'errore quadratico medio\n",
    "#e il coefficiente di indeterminazione sulla predizione fatta sul set di addestramento:\n",
    "\n",
    "mse_train = mean_squared_error(Y_train, Y_pred_train)\n",
    "R2_train = r2_score(Y_train, Y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: MSE= 4.116985074931599  R2= 0.9514303225914083\n"
     ]
    }
   ],
   "source": [
    "print(\"Train set: MSE= \" + str(mse_train) + \"  R2= \" + str(R2_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'errore è molto basso e il punteggio è molto alto.\n",
    "Questo ci potrebbe far pensare di aver trovato un modello ottimo, ma in realta potremmo avere overfitting. \n",
    "Per verificarlo dobbiamo fare la predizione sul testset, calcolare errore e punteggio, e confrontiamo con quelli relativi al trainset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: MSE= 29.550444547162094  R2= 0.6451057885504259\n"
     ]
    }
   ],
   "source": [
    "Y_pred_test = ll.predict(X_test_poly)\n",
    "\n",
    "mse_test = mean_squared_error(Y_test, Y_pred_test)\n",
    "R2_test = r2_score(Y_test, Y_pred_test)\n",
    "\n",
    "print(\"Test set: MSE= \" + str(mse_test) + \"  R2= \" + str(R2_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sia MSE che R2 sono decisamente peggiori rispetto a quelli del test di addestramento. QUindi ci troviamo sicuramente in Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Regolarizzazione per risolvere il problema dell'overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La regolarizzazione penalizza i pesi più grandi riducendo la complessita del modello, quindi riducendo la varianza e aumentando il bias, il che fa apparire il modello piu regolare e meno soggetto a fluttuazioni.\n",
    "Le principali tecniche di regolarizzazione sono 2: Regolarizzazione L2 e regolarizzazione L1.\n",
    "Entrambe funzionano aggiungendo una penalita ai pesi molto grandi alla funzione di costo durante l'addestramento.\n",
    "\n",
    "Per usare la regolarizzazione è necessario che tutti i dati siano sulla stessa scala. Sarà quindi necessario standardizzare o normalizzare il dataset.\n",
    "\n",
    "#### Regolarizzazione L2:\n",
    "Detta anche weight decay, questo termine è dato dalla somma dei quadrati dei pesi. Questo nuovo termine costringera il grdient descend a cercare il minio di questa nuova funzione di costo per valori dei pesi piu piccoli.\n",
    "Lambda è un altro iperparametro, e serve a controlare il peso che la regolarizzazione avra sul modello\n",
    "\n",
    "#### Regolarizzazione L1:\n",
    " Il termine da aggiungere alla funzione di costo durante l'addeestramento è la somma deò valore assoluto dei pesi.\n",
    " Questo nuovo termine porta il peso delle proprieta meno importanti a zero. \n",
    " Quindi dato che una proprieta con peso 0 viene totalmente esclusa dal modello, la regolarizzazione L1 ci permette di fare una selezione delle proprieta.\n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " Nella pratica la L2 fornisce quasi sempre risultati migliori della L1, ma una buona tecnica è di usarle entrambe in coppia.\n",
    " \n",
    " \n",
    " Abbiamo detto che Lambda è un iperparametro, e quindi va ottimizzato per il nostro modello.\n",
    " Come scegliere il suo valore?\n",
    " \n",
    " Se lambda = 0 , il termine di regolarizzazione sara uguale a 0, il che equivale a fare una regressione lineare regolare, e quindi non si risolve l'overfitting.\n",
    " Se lambda è troppo grande, il peso della pregolarizzazione sara troppo alto e la maggiorparte dei pesi verranno ridotti a 0, o in prossimita dello 0, il che porterebbe il modello in condizioni di underfitting.\n",
    "La soluzione corretta consiste nel cercare lambda in un range che va da 10^-4, ovvero 0,0001 e 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge, Lasso ed ElasticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "proveremo a contrastare l'overfitting usando la regolarizzazione che, come abbiamo visto, è una tecnica che ci permette  di ridurre la complessita di un modello dimunuendo la magnitudine dei coefficienti.\n",
    "\n",
    "Un modello di Machine Learning che applica la regolarizzazione L2 è la Ridge Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importiamo la classe ridge da SciKitLearn:\n",
    "\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando la regolarizzazione dobbiamo gestire un nuovo iperparametro: il parametro di regolarizzazione, detto Lambda (Nel caso di SciKitLearn viene chiamato Alpha).\n",
    "Andiamo a cercare il nostro modello regolarizzato su diversi valori di alpha:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creiamo un array di possibili valori di alpha, fra 0,0001 e 10:\n",
    "\n",
    "alphas = [0.0001, 0.001, 0.01, 0.1, 1, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALPHA=0.0001\n",
      "Train set: MSE=4.0992634048797  R2=0.9516393920395351\n",
      "Test set: MSE= 28.91761846311459 R2=0.6527058878898564\n",
      "ALPHA=0.001\n",
      "Train set: MSE=4.1135025099452385  R2=0.9514714077677846\n",
      "Test set: MSE= 28.420009267359223 R2=0.6586820627272876\n",
      "ALPHA=0.01\n",
      "Train set: MSE=4.208206127239228  R2=0.950354152286485\n",
      "Test set: MSE= 26.8132950181357 R2=0.6779783405072352\n",
      "ALPHA=0.1\n",
      "Train set: MSE=4.747028830954056  R2=0.9439974508597039\n",
      "Test set: MSE= 23.631755117362193 R2=0.7161879211610329\n",
      "ALPHA=1\n",
      "Train set: MSE=5.875947305341951  R2=0.9306791596529934\n",
      "Test set: MSE= 17.634584627529463 R2=0.7882125937009337\n",
      "ALPHA=10\n",
      "Train set: MSE=8.81275552173785  R2=0.8960324885854234\n",
      "Test set: MSE= 17.15971577477408 R2=0.79391566211913\n"
     ]
    }
   ],
   "source": [
    "#ora creiamo diversi modelli, uno per ogni valori di alpha, all'interno di un ciclo for\n",
    "\n",
    "for alpha in alphas:\n",
    "    print(\"ALPHA=\" +str(alpha))\n",
    "    model = Ridge(alpha=alpha)\n",
    "    model.fit(X_train_poly, Y_train)\n",
    "    \n",
    "    # Dopo aver costruito il modello andiamo a valutarlo sia sul set di addestramento che sul set di test.\n",
    "    #Quindi andiamo a fare le predizioni per entrambi i set:\n",
    "\n",
    "    Y_pred_train = model.predict(X_train_poly)\n",
    "    Y_pred_test = model.predict(X_test_poly)\n",
    "    \n",
    "    #Andiamo a calcolare l'errore quadratico medio e il coeff. di indeterminazione per entrambi i set:\n",
    "    \n",
    "    mse_train = mean_squared_error(Y_train, Y_pred_train)\n",
    "    mse_test = mean_squared_error(Y_test, Y_pred_test)\n",
    "    R2_train = r2_score(Y_train, Y_pred_train)\n",
    "    R2_test = r2_score(Y_test, Y_pred_test)\n",
    "    \n",
    "    # e li stampiamo per poterli confrontare:\n",
    "    \n",
    "    print(\"Train set: MSE=\" +str(mse_train) + \"  R2=\"+ str(R2_train))\n",
    "    print(\"Test set: MSE= \" + str(mse_test) + \" R2=\" + str(R2_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per Alpha (Lambda) fino a 1, l'algoritmo non riesce a risolvere l'overfitting, ma per alpha = 1 e 10 si raggiunge un R2 poco inferiore a 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Regression\n",
    "\n",
    "Proviamo ora ad utilizzare il Lasso, che è un modello di regressine lineare che applica la regolarizzazione L1, e quindi tende  portare a zero il peso di proprieta poco importanti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importiamo la classe Lasso da SciKitLearn:\n",
    "\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALPHA=0.0001\n",
      "Train set: MSE=5.391123652697097  R2=0.9363988132296843\n",
      "Test set: MSE= 29.701776720601217 R2=0.6432883230881412\n",
      "ALPHA=0.001\n",
      "Train set: MSE=5.407317548867128  R2=0.936207767525449\n",
      "Test set: MSE= 28.788018557306383 R2=0.654262353691998\n",
      "ALPHA=0.01\n",
      "Train set: MSE=6.0638588169003125  R2=0.9284622943178908\n",
      "Test set: MSE= 22.93324201265647 R2=0.7245769068863099\n",
      "ALPHA=0.1\n",
      "Train set: MSE=11.833211121207535  R2=0.8603989967405071\n",
      "Test set: MSE= 19.296152342816377 R2=0.7682575380960781\n",
      "ALPHA=1\n",
      "Train set: MSE=21.590985067091978  R2=0.7452827346818105\n",
      "Test set: MSE= 27.25804314512913 R2=0.6726370152499754\n",
      "ALPHA=10\n",
      "Train set: MSE=84.76451346994796  R2=0.0\n",
      "Test set: MSE= 83.76673764512785 R2=-0.0060197319476869016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 948.9527113282645, tolerance: 3.000663776836158\n",
      "  positive)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 886.5733620155494, tolerance: 3.000663776836158\n",
      "  positive)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 504.93622041518574, tolerance: 3.000663776836158\n",
      "  positive)\n"
     ]
    }
   ],
   "source": [
    "# facciamo la stessa cosa di prima, semplicemente cambiando il tip di modello da Ridge a Lasso:\n",
    "\n",
    "for alpha in alphas:\n",
    "    print(\"ALPHA=\" +str(alpha))\n",
    "    model = Lasso(alpha=alpha)\n",
    "    model.fit(X_train_poly, Y_train)\n",
    "    \n",
    "    # Dopo aver costruito il modello andiamo a valutarlo sia sul set di addestramento che sul set di test.\n",
    "    #Quindi andiamo a fare le predizioni per entrambi i set:\n",
    "\n",
    "    Y_pred_train = model.predict(X_train_poly)\n",
    "    Y_pred_test = model.predict(X_test_poly)\n",
    "    \n",
    "    #Andiamo a calcolare l'errore quadratico medio e il coeff. di indeterminazione per entrambi i set:\n",
    "    \n",
    "    mse_train = mean_squared_error(Y_train, Y_pred_train)\n",
    "    mse_test = mean_squared_error(Y_test, Y_pred_test)\n",
    "    R2_train = r2_score(Y_train, Y_pred_train)\n",
    "    R2_test = r2_score(Y_test, Y_pred_test)\n",
    "    \n",
    "    # e li stampiamo per poterli confrontare:\n",
    "    \n",
    "    print(\"Train set: MSE=\" +str(mse_train) + \"  R2=\"+ str(R2_train))\n",
    "    print(\"Test set: MSE= \" + str(mse_test) + \" R2=\" + str(R2_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notiamo che il punteggio migliore si è ottenuto con Alpha = 0.1, infatti R2 = 0.72\n",
    "mentre per valori maggiori di alpha, per esempio alpha = 10, l'effetto della regolarizzazione è troppo intenso, molti pesi vengono ridotti a 0 e ne risentono le performance del modello.\n",
    "\n",
    "La Regolarizzazione L2 ha dato risultati migliori.\n",
    "In generale conviene usare entrambi i tipi di regolarizzazione, L2 e L1, insieme.\n",
    "Un modello che ci consente di farlo è ElasticNet:\n",
    "\n",
    "#### ElasticNet:\n",
    "\n",
    "Questo modello fornisce un altro parametro aggiuntivo, l1_ratio, che indica a quale dei due tipi di regolarizzazione dare più importanza. Con un valore di 0.5 i due metodi verranno utilizzati con lo stesso peso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importiamo la classe da SciKitLearn:\n",
    "\n",
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALPHA=0.0001\n",
      "Train set: MSE=5.391059281137908  R2=0.9363995726460551\n",
      "Test set: MSE= 29.466017582883698 R2=0.6461197374561638\n",
      "ALPHA=0.001\n",
      "Train set: MSE=5.463124643400415  R2=0.9355493894819877\n",
      "Test set: MSE= 26.23899793865858 R2=0.6848755196286369\n",
      "ALPHA=0.01\n",
      "Train set: MSE=6.6699478752202905  R2=0.921312025490655\n",
      "Test set: MSE= 15.784424726986327 R2=0.8104325991533368\n",
      "ALPHA=0.1\n",
      "Train set: MSE=12.092531251957974  R2=0.8573396960952864\n",
      "Test set: MSE= 20.123693597792254 R2=0.7583189532244383\n",
      "ALPHA=1\n",
      "Train set: MSE=21.178857007859765  R2=0.7501447700119411\n",
      "Test set: MSE= 27.923580301576493 R2=0.6646440632674491\n",
      "ALPHA=10\n",
      "Train set: MSE=70.28359861834348  R2=0.1708369960353573\n",
      "Test set: MSE= 69.68198552608109 R2=0.16313498207951238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 966.4573759845673, tolerance: 3.000663776836158\n",
      "  positive)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1013.5668798465641, tolerance: 3.000663776836158\n",
      "  positive)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 993.001922022791, tolerance: 3.000663776836158\n",
      "  positive)\n"
     ]
    }
   ],
   "source": [
    "# facciamo la stessa cosa di prima, semplicemente cambiando il tip di modello da Ridge/Lasso a ElasticNet:\n",
    "\n",
    "for alpha in alphas:\n",
    "    print(\"ALPHA=\" +str(alpha))\n",
    "    \n",
    "    # dobbiamo specificare il parametro l1_ratio\n",
    "    model = ElasticNet(alpha=alpha, l1_ratio = 0.5)\n",
    "    model.fit(X_train_poly, Y_train)\n",
    "    \n",
    "    # Dopo aver costruito il modello andiamo a valutarlo sia sul set di addestramento che sul set di test.\n",
    "    #Quindi andiamo a fare le predizioni per entrambi i set:\n",
    "\n",
    "    Y_pred_train = model.predict(X_train_poly)\n",
    "    Y_pred_test = model.predict(X_test_poly)\n",
    "    \n",
    "    #Andiamo a calcolare l'errore quadratico medio e il coeff. di indeterminazione per entrambi i set:\n",
    "    \n",
    "    mse_train = mean_squared_error(Y_train, Y_pred_train)\n",
    "    mse_test = mean_squared_error(Y_test, Y_pred_test)\n",
    "    R2_train = r2_score(Y_train, Y_pred_train)\n",
    "    R2_test = r2_score(Y_test, Y_pred_test)\n",
    "    \n",
    "    # e li stampiamo per poterli confrontare:\n",
    "    \n",
    "    print(\"Train set: MSE=\" +str(mse_train) + \"  R2=\"+ str(R2_train))\n",
    "    print(\"Test set: MSE= \" + str(mse_test) + \" R2=\" + str(R2_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questo modello ha ottenuto il punteggio migliore per Alpha 0.1.\n",
    "Il risultato è migliore rispetto ai casi precedenti: l'errore è minore e il punteggio (il coeff. di indeterminazione) è maggiore, e l'overfitting è stato notevolmente ridotto.\n",
    " \n",
    "Quando si usa la regolarizzazione per eliminare l'overfitting, è necessario che tutti i dati siano sulla stessa scala, e quindi bisogna standardizzare, come abbiamo fatto in questo caso, oppure normalizzare."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
